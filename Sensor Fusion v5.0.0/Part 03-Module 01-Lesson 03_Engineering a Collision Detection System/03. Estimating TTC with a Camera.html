<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Estimating TTC with a Camera
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Engineering a Collision Detection System
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Collision Detection Basics.html">
       01. Collision Detection Basics
      </a>
     </li>
     <li class="">
      <a href="02. Estimating TTC with Lidar.html">
       02. Estimating TTC with Lidar
      </a>
     </li>
     <li class="">
      <a href="03. Estimating TTC with a Camera.html">
       03. Estimating TTC with a Camera
      </a>
     </li>
     <li class="">
      <a href="04. Course Structure.html">
       04. Course Structure
      </a>
     </li>
     <li class="">
      <a href="05. Early Fusion vs. Late Fusion.html">
       05. Early Fusion vs. Late Fusion
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          03. Estimating TTC with a Camera
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="estimating-ttc-with-a-camera">
          Estimating TTC with a Camera
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          ND313 C03 L02 A04 C23 Intro
         </p>
        </h3>
        <video controls="">
         <source src="03. ND313 C03 L02 A04 C23 Intro-h8WoErQle2U.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="03. ND313 C03 L02 A04 C23 Intro-h8WoErQle2U.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="measuring-ttc-without-distance">
          Measuring TTC without distance
         </h2>
         <p>
          Monocular cameras are not able to measure metric distances. They are passive sensors that rely on the ambient light which reflects off of objects into the camera lens. It is thus not possible to measure the runtime of light as with Lidar technology.
         </p>
         <p>
          To measure distance, a second camera would be needed. Given two images taken by two carefully aligned cameras (also called a
          <em>
           stereo setup
          </em>
          ) at the same time instant, one would have to locate common points of interest in both images (e.g. the tail lights of the preceding vehicle) and then triangulate their distance using camera geometry and perspective projection. For many years, automotive researchers have developed stereo cameras for the use in ADAS products and some of those have made it to market. Especially Mercedes-Benz has pioneered this technology and extensive information can be found here :
          <a href="http://www.6d-vision.com/" rel="noopener noreferrer" target="_blank">
           http://www.6d-vision.com/
          </a>
          . With more advanced ADAS products and with autonomous vehicles however, stereo cameras have started to disappear from the market due to their package size, the high price and the high computational load for finding corresponding features.
         </p>
         <p>
          Despite those limitations of the mono camera, let us see if there is a way to compute TTC without the need to measure distance. Let us consider the constant velocity motion model we introduced in a previous section of this course and think about a way to replace the metric distances d with something the camera can measure reliably, such as pixel distances directly on the image plane. In the following figure, you can see how the height
          <span class="mathquill ud-math">
           H
          </span>
          of the preceding vehicle can be mapped onto the image place using perspective projection. We can see that the same height
          <span class="mathquill ud-math">
           H
          </span>
          maps to different heights
          <span class="mathquill ud-math">
           h_0
          </span>
          and
          <span class="mathquill ud-math">
           h_1
          </span>
          in the image plane, depending on the distance
          <span class="mathquill ud-math">
           d_0
          </span>
          and
          <span class="mathquill ud-math">
           d_1
          </span>
          of the vehicle. It is obvious that there is a geometric relation between
          <span class="mathquill ud-math">
           h
          </span>
          ,
          <span class="mathquill ud-math">
           H
          </span>
          ,
          <span class="mathquill ud-math">
           d
          </span>
          and the focal length
          <span class="mathquill ud-math">
           f
          </span>
          of the pinhole camera - and this is what we want to exploit in the following.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Let us take a look at the following set of equations:
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage-1.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In (1) we use the focal length of the camera and a distance measurement
          <span class="mathquill ud-math">
           d_0
          </span>
          performed at time
          <span class="mathquill ud-math">
           t_0
          </span>
          to project the height
          <span class="mathquill ud-math">
           H
          </span>
          of the vehicle onto the image plane and thus to a height
          <span class="mathquill ud-math">
           h_0
          </span>
          in pixels. The same is done at time
          <span class="mathquill ud-math">
           t_1
          </span>
          , leading to a projected height
          <span class="mathquill ud-math">
           h_1
          </span>
          .
         </p>
         <p>
          In (2), we compute the ratio of the relative heights
          <span class="mathquill ud-math">
           h_0
          </span>
          and
          <span class="mathquill ud-math">
           h_1
          </span>
          . As both
          <span class="mathquill ud-math">
           H
          </span>
          and
          <span class="mathquill ud-math">
           f
          </span>
          are cancelled out, we can observe a direct relation between relative height
          <span class="mathquill ud-math">
           h
          </span>
          and absolute metric distance
          <span class="mathquill ud-math">
           d
          </span>
          . We can thus express the distance to the vehicle
          <span class="mathquill ud-math">
           d_0
          </span>
          as the product of
          <span class="mathquill ud-math">
           d_1
          </span>
          and the ratio of relative heights on the image plane.
         </p>
         <p>
          In (3), we substitute
          <span class="mathquill ud-math">
           d_0
          </span>
          in the equation for constant velocity and solve for
          <span class="mathquill ud-math">
           d_1
          </span>
          , which is now dependent on the constant relative velocity
          <span class="mathquill ud-math">
           v_0
          </span>
          , on the time between measuring
          <span class="mathquill ud-math">
           d_0
          </span>
          and
          <span class="mathquill ud-math">
           d_1
          </span>
          and on the ratio of relative heights on the image plane.
         </p>
         <p>
          In (4), the TTC is computed as the ratio of remaining distance to impact, which is
          <span class="mathquill ud-math">
           d_1
          </span>
          , and the constant velocity
          <span class="mathquill ud-math">
           v_0
          </span>
          . As we can easily see, the TTC now only consists of
          <span class="mathquill ud-math">
           \Delta t
          </span>
          ,
          <span class="mathquill ud-math">
           h_0
          </span>
          and
          <span class="mathquill ud-math">
           h_1
          </span>
          . Thus, it is possible to measure the time to collision by observing relative height change on the image sensor. Distance measurements are not needed and we can thus use a mono camera to estimate the time-to-collision by observing changes in relative height (also called
          <em>
           scale change
          </em>
          ) directly in the image.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="the-problem-with-bounding-box-detection">
          The Problem with Bounding Box Detection
         </h2>
         <p>
          In the figure below, a neural network has been used to locate vehicles in successive images of a monocular camera. For each vehicle, the network returns a bounding box, whose width and/or height could in principal be used to compute the height ratio in the TTC equation we derived in the last section.
         </p>
         <p>
          When observed closely however, it can be seen that the bounding boxes do not always reflect the true vehicle dimensions and the aspect ratio differs between images. Using bounding box height or width for TTC computation would thus lead to significant estimation errors.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/new-group.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In most engineering tasks, relying on a single measurement or property is not reliable enough. This holds especially true for safety-related products. Therefore, we want to consider wether there are further properties of vehicles and objects we can observe in an image.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="using-texture-keypoints-instead">
          Using Texture Keypoints Instead
         </h2>
         <p>
          Instead of relying on the detection of the vehicle as a whole we now want to analyze its structure on a smaller scale. If if were possible to locate uniquely identifiable keypoints that could be tracked from one frame to the next, we could use the distance between all keypoints on the vehicle relative to each other to compute a robust estimate of the height ratio in out TTC equation. The following figure illustrates the concept.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/new-group-1.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In (a), a set of keypoints has been detected and the relative distances between keypoints 1-7 have been computed. In (b), 4 keypoints have been matched between successive images (with keypoint 3 being a mismatch) using a higher-dimensional similarity measure called
          <em>
           descriptor
          </em>
          (more about that in the next lesson). The ratio of all relative distances between each other can be used to compute a reliable TTC estimate by replacing the height ratio
          <span class="mathquill ud-math">
           h_1 / h_0
          </span>
          with the mean or median of all distance ratios
          <span class="mathquill ud-math">
           d_k / d_k'
          </span>
          .
         </p>
         <p>
          The following figure shows several example of relative distances between keypoints as an overlay over a highway driving scene (only the preceding vehicle is highlighted).
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage-2.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="computing-ttc-from-relative-keypoint-distances">
          Computing TTC from Relative Keypoint Distances
         </h2>
         <p>
          In the code examples in this course, matching keypoints between images are packaged into an OpenCV data structure called
          <code>
           cv::DMatch
          </code>
          . The structure elements we will be using in this course are
          <code>
           queryIdx
          </code>
          , which is the index of a keypoint in the current frame, and
          <code>
           trainIdx
          </code>
          , which is the index of the matched keypoint in the previous frame.
         </p>
         <p>
          All matched keypoints are stored in a dynamic list, which is then passed to a function called
          <code>
           computeTTCCamera
          </code>
          , which returns the time-to-collision for each object in the scene. Let us take a look at this function in the following.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="exercise">
          Exercise
         </h2>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          ND313 C03 L02 A05 C23 Quiz
         </p>
        </h3>
        <video controls="">
         <source src="03. ND313 C03 L02 A05 C23 Quiz-2eeP2SWrdiA.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="03. ND313 C03 L02 A05 C23 Quiz-2eeP2SWrdiA.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Imagine a set of associated keypoint between two successive frames which contain a large number of mismatches. Computing the mean distance ratio as in the function we just discussed would presumably lead to a faulty calculation of the TTC. A more robust way of computing the average of a dataset with outliers is to use the median instead. In the code below, replace
          <code>
           meanDistRatio
          </code>
          with a variable
          <code>
           medianDistRatio
          </code>
          and do not forget to consider both an even and an odd number of values in the vector
          <code>
           distRatios
          </code>
          .
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div class="jumbotron">
         <h3>
          Workspace
         </h3>
         <p class="lead">
          This section contains either a workspace (it can be a
          <a href="http://jupyter.org/" target="_blank">
           Jupyter
      Notebook
          </a>
          workspace or an online code editor work space, etc.) and it cannot be automatically downloaded to be
    generated here. Please access the classroom with your account and manually download the workspace to your local
    machine. Note that for some courses, Udacity upload the workspace files onto
          <a href="https://github.com/udacity" target="_blank">
           https://github.com/udacity
          </a>
          , so you may be able to download them there.
         </p>
         <h4>
          Workspace Information:
         </h4>
         <ul>
          <li>
           <strong>
            Default file path:
           </strong>
          </li>
          <li>
           <strong>
            Workspace type:
           </strong>
           react
          </li>
          <li>
           <strong>
            Opened files (when workspace is loaded):
           </strong>
           n/a
          </li>
          <li>
           <strong>
            userCode:
           </strong>
           <br/>
           <code>
            <p>
             export CXX=g++-7
             <br>
              export CXXFLAGS=-std=c++17
             </br>
            </p>
           </code>
          </li>
         </ul>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="04. Course Structure.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('03. Estimating TTC with a Camera')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
