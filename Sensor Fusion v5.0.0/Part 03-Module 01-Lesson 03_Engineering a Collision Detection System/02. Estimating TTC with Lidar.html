<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Estimating TTC with Lidar
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Engineering a Collision Detection System
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Collision Detection Basics.html">
       01. Collision Detection Basics
      </a>
     </li>
     <li class="">
      <a href="02. Estimating TTC with Lidar.html">
       02. Estimating TTC with Lidar
      </a>
     </li>
     <li class="">
      <a href="03. Estimating TTC with a Camera.html">
       03. Estimating TTC with a Camera
      </a>
     </li>
     <li class="">
      <a href="04. Course Structure.html">
       04. Course Structure
      </a>
     </li>
     <li class="">
      <a href="05. Early Fusion vs. Late Fusion.html">
       05. Early Fusion vs. Late Fusion
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          02. Estimating TTC with Lidar
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="estimating-ttc-with-lidar">
          Estimating TTC with Lidar
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          ND313 C03 L02 A02 C22 Intro
         </p>
        </h3>
        <video controls="">
         <source src="02. ND313 C03 L02 A02 C22 Intro-961l-IJpA6w.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="02. ND313 C03 L02 A02 C22 Intro-961l-IJpA6w.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="the-math-behind-time-to-collision-ttc">
          The Math Behind Time-to-Collision (TTC)
         </h2>
         <p>
          In the following, let us assume that our CAS-equipped vehicle is using a Lidar sensor to take distance measurements on preceding vehicles. The sensor in this scenario will give us the distance to the closest 3D point in the path of driving. In the figure below, the closest point is indicated by a red line emanating from a Lidar sensor on top of the CAS vehicle.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Based on the model of a constant-velocity we discussed in the last section, the velocity
          <span class="mathquill ud-math">
           v_0
          </span>
          can be computed from two successive Lidar measurements as follows:
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage-1.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Once the relative velocity
          <span class="mathquill ud-math">
           v_0
          </span>
          is known, the time to collision can easily be computed by dividing the remaining distance between both vehicles by
          <span class="mathquill ud-math">
           v_0
          </span>
          . So given a Lidar sensor which is able to take precise distance measurements, a system for TTC estimation can be developed based based on a CVM and on the set of equations shown above. Note however that a radar sensor would be the superior solution for TTC computation as it can directly measure the relative speed, whereas with the Lidar sensor we need to compute
          <span class="mathquill ud-math">
           v_0
          </span>
          from two (noisy) distance measurements.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="preparing-the-lidar-point-cloud">
          Preparing the Lidar Point Cloud
         </h2>
         <p>
          The following image shows a Lidar point cloud as an overlay over a camera image taken in a highway scenario with a preceding vehicle directly in the path of driving. Distance to the sensor is color-coded (green is far away, red is close). On the left side, a bird-view perspective of the Lidar points is shown as well.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/ebene.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          As can easily be seen, the Lidar sensor provides measurements on the vehicles as well as on the road surface. Also, some 3D points in the camera image do not seem accurate when compared to their surrounding neighbors. Especially the points near the roof of the preceding vehicle differ in color from the points on the tailgate.
         </p>
         <p>
          As measurement accuracy is correlated to the amount of light reflected from an object, it makes sense to consider the reflectiveness r of each Lidar point which we can access in addition to the x, y and z coordinates. The image below highlights high reflectiveness with green, whereas regions with low reflectiveness are shown as red. An analysis of the associated reflectivity of the point cloud shows that such deviations often occur in regions with reduced reflectiveness.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/draggedimage-2.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In order to derive a stable TTC measurement from the given point cloud, two main steps have to be performed:
         </p>
         <ol>
          <li>
           Remove measurements on the road surface
          </li>
          <li>
           Remove measurements with low reflectivity
          </li>
         </ol>
         <p>
          In the figure below, Lidar points are shown in a top-view perspective and as an image overlay after applying the filtering. After removing Lidar points in this manner, it is now much easier to derive the distance d(t) to the preceding vehicle.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/pfeile.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In a later lesson, you will learn how to project Lidar points into the camera image and how to perform the removal procedure as seen in the above examples. For now, let us assume that for each time step dt, the Lidar sensor would return the distance d(t+dt) to the preceding vehicle.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="computing-ttc-from-distance-measurements">
          Computing TTC from Distance Measurements
         </h2>
         <p>
          In the code examples in this course, Lidar points are packaged into a data structure called LidarPoints. As seen below, the structure consists of the point coordinates x (forward), y (left) an z (up) in metric coordinates and of the point reflectivity r on a scale between 0 and 1 (high reflectivity).
         </p>
         <pre><code class="cpp language-cpp">struct LidarPoint { // single lidar point in space
    double x, y, z; // point position in m
    double r; // point reflectivity in the range 0-1
};</code></pre>
         <p>
          In order to compute the TTC, we need to find the distance to the closest Lidar point in the path of driving. In the figure below, Lidar measurements located on the tailgate of the preceding vehicle are measured at times
          <span class="mathquill ud-math">
           t_0
          </span>
          (green) and
          <span class="mathquill ud-math">
           t_1
          </span>
          (red). It can be seen, that the distance to the vehicle has decreased slightly between both time instants.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/new-group.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The following code searches for the closest point in the point cloud associated with
          <span class="mathquill ud-math">
           t_0
          </span>
          (
          <code>
           lidarPointsPrev
          </code>
          ) and in the point cloud associated with
          <span class="mathquill ud-math">
           t_1
          </span>
          (
          <code>
           lidarPointsCurr
          </code>
          ). After finding the distance to the closest points respectively, the TTC is computed based on the formula we derived at the beginning of this section.
         </p>
         <pre><code class="cpp language-cpp">void computeTTCLidar(std::vector&lt;LidarPoint&gt; &amp;lidarPointsPrev, 
                     std::vector&lt;LidarPoint&gt; &amp;lidarPointsCurr, double &amp;TTC)
{
    // auxiliary variables
    double dT = 0.1; // time between two measurements in seconds

    // find closest distance to Lidar points 
    double minXPrev = 1e9, minXCurr = 1e9;
    for(auto it=lidarPointsPrev.begin(); it!=lidarPointsPrev.end(); ++it) {
        minXPrev = minXPrev&gt;it-&gt;x ? it-&gt;x : minXPrev;
    }

    for(auto it=lidarPointsCurr.begin(); it!=lidarPointsCurr.end(); ++it) {
        minXCurr = minXCurr&gt;it-&gt;x ? it-&gt;x : minXCurr;
    }

    // compute TTC from both measurements
    TTC = minXCurr * dT / (minXPrev-minXCurr);
}</code></pre>
         <p>
          Even though Lidar is a reliable sensor, erroneous measurements may still occur. As seen in the figure above, a small number of points is located behind the tailgate, seemingly without connection to the vehicle. When searching for the closest points, such measurements will pose a problem as the estimated distance will be too small. There are ways to avoid such errors by post-processing the point cloud, but there will be no guarantee that such problems will never occur in practice. It is thus a good idea to perform a more robust computation of minXCurr and minXPrev which is able to cope with a certain number of outliers (in the final project, you will do this) and also look at a second sensor which is able to compute the TTC, such as the camera.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="exercise">
          Exercise
         </h2>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          ND313 C03 L02 A03 C22 Quiz
         </p>
        </h3>
        <video controls="">
         <source src="02. ND313 C03 L02 A03 C22 Quiz-YWatEESYasw.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="02. ND313 C03 L02 A03 C22 Quiz-YWatEESYasw.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          In the workspace below, extend the function
          <code>
           computeTTCLidar
          </code>
          shown above so that only Lidar points within a narrow corridor whose width is defined by a variable laneWidth are considered during minimum search. The width of the corridor should be set to 4 meters.
         </p>
         <p>
          You can run your code as usual by creating a
          <code>
           build
          </code>
          directory in
          <code>
           TTC_lidar
          </code>
          . Then use the following steps from within the
          <code>
           build
          </code>
          directory:
         </p>
         <ol>
          <li>
           <code>
            cmake ..
           </code>
          </li>
          <li>
           <code>
            make
           </code>
          </li>
          <li>
           <code>
            ./compute_ttc_lidar
           </code>
          </li>
         </ol>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div class="jumbotron">
         <h3>
          Workspace
         </h3>
         <p class="lead">
          This section contains either a workspace (it can be a
          <a href="http://jupyter.org/" target="_blank">
           Jupyter
      Notebook
          </a>
          workspace or an online code editor work space, etc.) and it cannot be automatically downloaded to be
    generated here. Please access the classroom with your account and manually download the workspace to your local
    machine. Note that for some courses, Udacity upload the workspace files onto
          <a href="https://github.com/udacity" target="_blank">
           https://github.com/udacity
          </a>
          , so you may be able to download them there.
         </p>
         <h4>
          Workspace Information:
         </h4>
         <ul>
          <li>
           <strong>
            Default file path:
           </strong>
          </li>
          <li>
           <strong>
            Workspace type:
           </strong>
           react
          </li>
          <li>
           <strong>
            Opened files (when workspace is loaded):
           </strong>
           n/a
          </li>
          <li>
           <strong>
            userCode:
           </strong>
           <br/>
           <code>
            <p>
             export CXX=g++-7
             <br>
              export CXXFLAGS=-std=c++17
             </br>
            </p>
           </code>
          </li>
         </ul>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="03. Estimating TTC with a Camera.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('02. Estimating TTC with Lidar')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
