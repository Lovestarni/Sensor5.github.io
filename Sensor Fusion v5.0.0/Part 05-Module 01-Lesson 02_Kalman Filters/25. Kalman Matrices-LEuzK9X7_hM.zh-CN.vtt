WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.000
这是我的代码

00:00:02.000 --> 00:00:04.000
如果你做对了

00:00:04.000 --> 00:00:09.000
我会为你感到非常骄傲

00:00:09.000 --> 00:00:12.000
因为你完成的这项任务 往往需要很多堂课

00:00:12.000 --> 00:00:16.000
才能解释清楚 而你却只上了一堂课

00:00:16.000 --> 00:00:19.000
就了解了其精髓所在 并写出了一段

00:00:19.000 --> 00:00:23.000
非常关键的代码 而且这段代码可以多次重用

00:00:23.000 --> 00:00:27.000
这是谷歌的无人驾驶车能够追踪其他车辆的核心所在

00:00:27.000 --> 00:00:30.000
这是逐行实现

00:00:30.000 --> 00:00:33.000
我之前说过的测量值更新和预测

00:00:33.000 --> 00:00:36.000
你会发现

00:00:36.000 --> 00:00:39.000
它使用我的矩阵类准确地

00:00:39.000 --> 00:00:42.000
逐步实现了我展示过的内容

00:00:42.000 --> 00:00:44.000
非常不简单

00:00:44.000 --> 00:00:47.000
我们必须对第 n 次测量创建测量矩阵

00:00:47.000 --> 00:00:50.000
这个问题求解时 你可能会这样

00:00:50.000 --> 00:00:52.000
误差计算

00:00:52.000 --> 00:00:55.000
计算矩阵 S 时用到了转置

00:00:55.000 --> 00:00:58.000
计算卡尔曼增益 K 时用到了求逆矩阵

00:00:58.000 --> 00:01:03.000
回到我下面的预测和测量值更新

00:01:03.000 --> 00:01:05.000
然后 这是预测步骤

00:01:05.000 --> 00:01:09.000
你可以看到 它准确实现了我在这里

00:01:09.000 --> 00:01:12.000
的两个方程中所展现的内容

00:01:12.000 --> 00:01:16.000
我知道这里涉及到编程

00:01:16.000 --> 00:01:18.000
如果你能完成 我会非常吃惊

00:01:18.000 --> 00:01:22.000
如果你已经完成好 说明你已取得了令人赞叹的成就

00:01:22.000 --> 00:01:25.000
你现在已经理解了卡尔曼滤波器

00:01:25.000 --> 00:01:28.000
并且使用我给你写的非常机械的矩阵类

00:01:28.000 --> 00:01:33.000
实现了一个多维

00:01:33.000 --> 00:01:35.000
卡尔曼滤波器

00:01:35.000 --> 00:01:38.000
你运行了这个滤波器 结果非常好

00:01:38.000 --> 00:01:44.000
一系列的位置预测 1、2、3

00:01:44.000 --> 00:01:47.000
让你做出了预测

00:01:47.000 --> 00:01:51.000
并了解了移动对象的速度

00:01:51.000 --> 00:01:54.000
这些是你刚刚实现的方程式

00:01:54.000 --> 00:01:56.000
祝贺你！

00:01:56.000 --> 00:01:59.000
你已经真正理解了这些基础知识

00:01:59.000 --> 00:02:02.000
而这些是人工智能和

00:02:02.000 --> 00:02:05.000
打造无人驾驶车的必备知识

00:02:05.000 --> 00:02:09.000
你有效地实现了寻找其他车辆的方法

00:02:09.000 --> 00:02:12.000
下面 我为这个方法提供一个场景

00:02:12.000 --> 00:02:14.000
这是一台谷歌的无人驾驶车

00:02:14.000 --> 00:02:16.000
这是另一辆车

00:02:16.000 --> 00:02:21.000
我们的谷歌无人驾驶车使用前保险杠上的雷达

00:02:21.000 --> 00:02:24.000
来测量与其他车辆的距离

00:02:24.000 --> 00:02:27.000
同时给出了估计速度时的误差

00:02:27.000 --> 00:02:30.000
它还同时使用激光雷达

00:02:30.000 --> 00:02:33.000
测量与其他车辆的距离 但没测量速度

00:02:33.000 --> 00:02:36.000
在上面同样的场景中

00:02:36.000 --> 00:02:38.000
这里是谷歌的车

00:02:38.000 --> 00:02:40.000
它位于地图上的某一点

00:02:40.000 --> 00:02:45.000
这是另一辆车 还有另一辆

00:02:45.000 --> 00:02:51.000
谷歌的车使用雷达和激光估算

00:02:51.000 --> 00:02:54.000
所有这些车辆的距离和速度

00:02:54.000 --> 00:02:58.000
这个过程中借助了卡尔曼滤波器

00:02:58.000 --> 00:03:00.000
我们获得了来自激光雷达的距离数据

00:03:00.000 --> 00:03:07.000
并且使用了状态空间 如这个 x 和 y的相对距离

00:03:07.000 --> 00:03:11.000
以及 x 和 y 的相对速度 得到了我刚才展示的

00:03:11.000 --> 00:03:15.000
类型的状态转移矩阵

00:03:15.000 --> 00:03:18.000
最终找到了其他车辆的位置 这就是你刚刚

00:03:18.000 --> 00:03:21.000
学习和编程的内容

00:03:21.000 --> 00:03:24.000
我没有告诉你如何从雷达和激光数据中提取位置

00:03:24.000 --> 00:03:26.000
我们把这个问题叫做对应点问题（correspondence problem）

00:03:26.000 --> 00:03:28.000
有时候 你不知道哪辆车是哪辆车

00:03:28.000 --> 00:03:31.000
我们这里不深入探讨

00:03:31.000 --> 00:03:34.000
但你已经知道了这个解决方案的核心

00:03:34.000 --> 00:03:36.000
而且能够编程实现了

00:03:36.000 --> 00:03:38.000
如果你碰到这种场景

00:03:38.000 --> 00:03:42.000
你可以使用距离数据 如激光和雷达数据

00:03:42.000 --> 00:03:44.000
并创建一个合理的算法 利用

00:03:44.000 --> 00:03:47.000
其他车辆的瞬时测量值

00:03:47.000 --> 00:03:51.000
而不是车辆位置的估算值 再加上车辆速度

00:03:51.000 --> 00:03:53.000
这是了不起的成就

00:03:53.000 --> 00:03:55.000
祝贺你取得巨大进步

00:03:55.000 --> 00:03:57.000
既然你已经学到了这里

00:03:57.000 --> 00:04:01.000
我向你保证 你刚刚掌握了

00:04:01.000 --> 00:04:03.000
这堂课上最困难的一部分

00:04:03.000 --> 99:59:59.999
祝贺你！

