WEBVTT
Kind: captions
Language: en

00:00:02.750 --> 00:00:06.269
Makes a lot of sense to have multiple cameras on

00:00:06.269 --> 00:00:08.955
a self-driving car because you have different use cases.

00:00:08.955 --> 00:00:12.689
You want to have different field of views.

00:00:12.689 --> 00:00:14.369
Basically, for a tailor lens,

00:00:14.369 --> 00:00:15.599
you want to see further away.

00:00:15.599 --> 00:00:18.899
You will have wide-angle lenses for the near-field around the car.

00:00:18.899 --> 00:00:23.579
You have different chips that cover different spectrums for night time driving,

00:00:23.579 --> 00:00:24.779
for high dynamic range.

00:00:24.780 --> 00:00:28.050
So there is a various number of applications,

00:00:28.050 --> 00:00:31.839
and there are specialized cameras for each of those fields.

00:00:33.920 --> 00:00:37.859
Camera-only depth perception can be very reliable,

00:00:37.859 --> 00:00:39.344
but mostly in the near field.

00:00:39.344 --> 00:00:42.429
In the far-field, it's getting really difficult.

00:00:44.509 --> 00:00:49.250
The way we use different cameras is basically not

00:00:49.250 --> 00:00:53.090
by relative synchronization or stitching of images,

00:00:53.090 --> 00:00:55.235
but for each camera,

00:00:55.234 --> 00:00:59.195
we basically want to do an absolute calibration with respect to

00:00:59.195 --> 00:01:02.119
a common time frame or common position

00:01:02.119 --> 00:01:05.239
that is usually the rear axle of the vehicle for instance.

00:01:05.239 --> 00:01:08.239
If we have this intrinsic and extrinsic calibration,

00:01:08.239 --> 00:01:13.079
we can map everything into one holistic global frame.

00:01:15.219 --> 00:01:18.109
Cameras are really great because they have

00:01:18.109 --> 00:01:21.935
a very high resolution compared to other sensors like LIDAR and RADAR.

00:01:21.935 --> 00:01:26.754
So they can be used for classification scene interpretation.

00:01:26.754 --> 00:01:29.629
Works much better as compared to others.

00:01:29.629 --> 00:01:31.789
Traffic light detection for instance,

00:01:31.790 --> 00:01:36.070
is one application where really only the camera can do the job,

00:01:36.069 --> 00:01:39.239
no other sensor can see the light states.

00:01:41.409 --> 00:01:47.000
So there are some circumstances where cameras have challenges for instance,

00:01:47.000 --> 00:01:52.489
at nighttime driving, the sensitivity even if you have a high sensitive chip,

00:01:52.489 --> 00:01:56.039
and high dynamic range, might still not be sufficient to detect objects.

00:01:56.040 --> 00:01:58.880
There is also a problem with detecting or

00:01:58.879 --> 00:02:02.224
measuring distance very precisely in the far field.

00:02:02.224 --> 00:02:06.244
So because of the high resolution in a radial this direction,

00:02:06.245 --> 00:02:07.625
you can see cross traffic,

00:02:07.625 --> 00:02:09.560
if you consider a front-facing camera.

00:02:09.560 --> 00:02:11.719
You can see close traffic really well,

00:02:11.719 --> 00:02:13.534
and measure the velocity really well,

00:02:13.534 --> 00:02:15.079
but if you have oncoming traffic,

00:02:15.080 --> 00:02:18.750
it is really difficult to detect that velocity accurately.

